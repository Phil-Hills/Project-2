# -*- coding: utf-8 -*-
"""updated_project_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-TCmcLGVqsKs6_pp4UUo0Ybja99WH524

# Risk Analyzer
"""

# Imports 

import pandas as pd
import numpy as np
from pathlib import Path
import hvplot.pandas
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.preprocessing import StandardScaler
from pandas.tseries.offsets import DateOffset
from sklearn.metrics import classification_report

pip install hvplot

"""---

### Import the csv into a Pandas DataFrame.
"""

# Import the GOOG.csv into a Pandas Dataframe
goog_df = pd.read_csv(Path("/content/GOOG.csv"),
                       index_col='Date',
                       infer_datetime_format=True,
                       parse_dates=True)

# Review the DataFrame
goog_df.head()

# Filter the close column
G_signals_df = goog_df.loc[:, ["Close"]]

# pct_change function to generate returns from close prices
G_signals_df["Actual Returns"] = G_signals_df["Close"].pct_change()

# Drop all NaN values from the DataFrame
G_signals_df = G_signals_df.dropna()

# Review the DataFrame
display(G_signals_df.head())
display(G_signals_df.tail())

"""## Generate trading signals using short- and long-window SMA values. """

# Set the short window and long window
short_window = 50
long_window = 100

# Generate the fast and slow simple moving averages 
G_signals_df['SMA_Fast'] = G_signals_df['Close'].rolling(window=short_window).mean()
G_signals_df['SMA_Slow'] = G_signals_df['Close'].rolling(window=long_window).mean()
G_signals_df['Signal'] = 0.0
G_signals_df = G_signals_df.dropna()

# Review the DataFrame
display(G_signals_df.head())
display(G_signals_df.tail())

# Initialize the new Signal column
#G_signals_df['Signal'] = 0.0

# Generate the trading signal 0 or 1,
# where 1 is the short-window (SMA_Fast) greater than the long-window (SMA_Slow)
# and 0 is when the condition is not met
G_signals_df["Signal"][short_window:] = np.where(
    G_signals_df["SMA_Slow"][short_window:] < G_signals_df["SMA_Fast"][short_window:], 1.0, 0.0
)

# Review the DataFrame
G_signals_df.tail(10)

G_signals_df['Signal'].value_counts()

# Calculate the strategy returns and add them to the signals_df DataFrame
G_signals_df['Strategy Returns'] = G_signals_df['Actual Returns'] * G_signals_df['Signal'].shift()

# Review the DataFrame
display(G_signals_df.head())
display(G_signals_df.tail())

# Plot Strategy Returns to examine performance
(1 + G_signals_df[['Strategy Returns']]).cumprod().plot()

# Calculate the points in time at which a position should be taken, 1 or -1
G_signals_df['Entry/Exit'] = G_signals_df['Signal'].diff()

# Review the DataFrame
G_signals_df.tail(10)

"""### Backtesting The Strategy"""

# Set the initial capital
initial_capital = float(100000)

# Set the share size
share_size = 500

# Take a 500 share position where the dual moving average crossover is 1 (SMA50 is greater than SMA100)
G_signals_df["Position"] = share_size * G_signals_df["Signal"]

# Find the points in time where a 500 share position is bought or sold
G_signals_df["Entry/Exit Position"] = G_signals_df["Position"].diff()

# Multiply share price by entry/exit positions and get the cumulatively sum
G_signals_df["Portfolio Holdings"] = (
    G_signals_df["Close"] * G_signals_df["Entry/Exit Position"].cumsum()
)

# Subtract the initial capital by the portfolio holdings to get the amount of liquid cash in the portfolio
G_signals_df["Portfolio Cash"] = (
    initial_capital - (G_signals_df["Close"] * G_signals_df["Entry/Exit Position"]).cumsum()
)

# Get the total portfolio value by adding the cash amount by the portfolio holdings (or investments)
G_signals_df["Portfolio Total"] = (
    G_signals_df["Portfolio Cash"] + G_signals_df["Portfolio Holdings"]
)

# Calculate the portfolio daily returns
G_signals_df["Portfolio Daily Returns"] = G_signals_df["Portfolio Total"].pct_change()

# Calculate the cumulative returns
G_signals_df["Portfolio Cumulative Returns"] = (
    1 + G_signals_df["Portfolio Daily Returns"]
).cumprod() - 1


# Print the DataFrame
G_signals_df.head(10).dropna()

"""## Plot Entry/Exit Points of Backtest Results"""

# Visualize exit positions relative to total portfolio value
entry = G_signals_df[G_signals_df["Entry/Exit"] == 1.0]["Portfolio Total"].hvplot.scatter(
    color='purple',
    marker='^',
    legend=False, 
    ylabel="Total Portfolio Value", 
    width=1000, 
    height=400
)

# Visualize entry positions relative to total portfolio value
exit = G_signals_df[G_signals_df["Entry/Exit"] == -1.0]["Portfolio Total"].hvplot.scatter(
    color='yellow',
    marker='v',
    legend=False, 
    ylabel="Total Portfolio Value", 
    width=1000, 
    height=400
)

# Visualize the total portoflio value 
total_portfolio_value = G_signals_df[['Portfolio Total']].hvplot(
    line_color='lightgray',
    ylabel='Total Portfolio Value',
    width=1000,
    height=400
)

# Overlay the plots
portfolio_entry_exit_plot = total_portfolio_value * entry * exit
portfolio_entry_exit_plot.opts(
    title="GOOGLE - Total Portfolio Value",
    yformatter='%.0f'
)

"""### Prepare Portfolio Evaluation Metrics DataFrame"""

# Create the list of the metric names
metrics = [
    'Annualized Return',
    'Cumulative Returns',
    'Annual Volatility',
    'Sharpe Ratio',
    'Sortino Ratio'
]

# Create a list that holds the column name
columns = ['Backtest']

# Initialize the DataFrame with index set to evaluation metrics and columns 
portfolio_evaluation_df = pd.DataFrame(index=metrics, columns=columns)

# Review the DataFrame
portfolio_evaluation_df

# Calculate the Annualized return metric
portfolio_evaluation_df.loc['Annualized Return'] = (
    G_signals_df['Portfolio Daily Returns'].mean() * 252
)

# Calculate the Cumulative returns metric
portfolio_evaluation_df.loc['Cumulative Returns'] = G_signals_df['Portfolio Cumulative Returns'][-1]

# Calculate the Annual volatility metric
portfolio_evaluation_df.loc['Annual Volatility'] = (
    G_signals_df['Portfolio Daily Returns'].std() * np.sqrt(252)
)

# Calculate the Sharpe ratio
portfolio_evaluation_df.loc['Sharpe Ratio'] = (
    G_signals_df['Portfolio Daily Returns'].mean() * 252) / (
    G_signals_df['Portfolio Daily Returns'].std() * np.sqrt(252)
)

G_signals_df = G_signals_df.loc[:,~G_signals_df.columns.duplicated()]

# Calculate the Sortino ratio
# Start by calculating the downside return values

# Create a DataFrame that contains the Portfolio Daily Returns column
sortino_ratio_df = G_signals_df[['Portfolio Daily Returns']]

# Create a column to hold downside return values
sortino_ratio_df.loc[:,'Downside Returns'] = 0

# Find Portfolio Daily Returns values less than 0, 
# square those values, and add them to the Downside Returns column
sortino_ratio_df.loc[sortino_ratio_df['Portfolio Daily Returns'] < 0, 
                     'Downside Returns'] = sortino_ratio_df['Portfolio Daily Returns']**2

# Calculate the annualized return value
annualized_return = sortino_ratio_df['Portfolio Daily Returns'].mean() * 252

# Calculate the annualized downside standard deviation value
downside_standard_deviation = np.sqrt(sortino_ratio_df['Downside Returns'].mean()) * np.sqrt(252)

# Divide the annualized return value by the downside standard deviation value
sortino_ratio = annualized_return/downside_standard_deviation

# Add the Sortino ratio to the evaluation DataFrame
portfolio_evaluation_df.loc['Sortino Ratio'] = sortino_ratio

# Review the portfolio evaluation DataFrame
portfolio_evaluation_df

"""### Split the data into training and testing datasets."""

# Assign a copy of the sma_fast and sma_slow columns to a features DataFrame called X
X = G_signals_df[['SMA_Fast', 'SMA_Slow']].shift().dropna()

# Review the DataFrame
X.head()

# Create the target set selecting the Signal column and assiging it to y
y = G_signals_df['Signal']

# Review the value counts
y.value_counts()

# Select the start of the training period
training_begin = X.index.min()
#training_begin = pd.to_datetime("2019-01-01 00:00:00")
#training_begin = pd.to_datetime("2018-01-01 00:00:00")

# Display the training begin date
print(training_begin)

# Select the ending period for the training data with an offset of 3 months
training_end = X.index.min() + DateOffset(months=3)
#training_end = training_begin + DateOffset(months=12)
#training_end = pd.to_datetime("2019-12-31 00:00:00")

# Display the training end date
print(training_end)

# Generate the X_train and y_train DataFrames
X_train = X.loc[training_begin:training_end]
y_train = y.loc[training_begin:training_end]

# Review the X_train DataFrame
display(X_train.head())
display(X_train.tail())

# Generate the X_test and y_test DataFrames
X_test = X.loc[training_end+DateOffset(hours=1):]
y_test = y.loc[training_end+DateOffset(hours=1):]

# Review the X_test DataFrame
display(X_test.head())
display(X_test.tail())

# Scale the features DataFrames

# Create a StandardScaler instance
scaler = StandardScaler()

# Apply the scaler model to fit the X-train data
X_scaler = scaler.fit(X_train)

# Transform the X_train and X_test DataFrames using the X_scaler
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)

"""### Use the `SVC` classifier model to fit the training data and make predictions based on the testing data"""

# From SVM, instantiate SVC classifier model instance
svm_model = svm.SVC()
 
# Fit the model to the data using the training data
svm_model = svm_model.fit(X_train_scaled, y_train)
 
# Use the testing data to make the model predictions
svm_pred = svm_model.predict(X_test_scaled)

# Review the model's predicted values
print(svm_pred[-10:])
print(y_test[-10:].values)

"""### Review the classification report associated with the `SVC` model predictions. """

# Use a classification report to evaluate the model using the predictions and testing data
svm_testing_report = classification_report(y_test,svm_pred)

# Print the classification report
print(svm_testing_report)

G_signals_df[G_signals_df.index.duplicated()]

G_signals_df = G_signals_df[~G_signals_df.index.duplicated()]

"""### Create a predictions DataFrame that contains columns for “Predicted” values, “Actual Returns”, and “Strategy Returns”."""

# Create a new empty predictions DataFrame.

# Create a predictions DataFrame
predictions_df = pd.DataFrame(index = X_test.index)

# Add the SVM model predictions to the DataFrame
predictions_df['Predicted'] = svm_pred

# Add the actual returns to the DataFrame
predictions_df['Actual Returns'] = G_signals_df["Actual Returns"]

# Add the strategy returns to the DataFrame
predictions_df['Strategy Returns'] = predictions_df['Actual Returns'] * predictions_df['Predicted']

# Review the DataFrame
display(predictions_df.head())
display(predictions_df.tail())

"""### A cumulative return plot that shows the actual returns vs. the strategy returns"""

# Plot the actual returns versus the strategy returns
returns_plot = (1 + predictions_df[["Actual Returns","Strategy Returns"]]).cumprod().hvplot(width = 1000, height = 400)
returns_plot

"""---

## New Machine Learning Classifier

### Import a new classifier `LogisticRegression`
"""

# Import a new classifier from SKLearn
from sklearn.linear_model import LogisticRegression

# Initiate the model instance
loreg_model = LogisticRegression()

# Fit the model using the training data
loreg_model = loreg_model.fit(X_train_scaled,y_train)

# Use the testing dataset to generate the predictions for the new model
pred = loreg_model.predict(X_test_scaled)

# Review the model's predicted values
pred[:10]

"""### Backtest the new model to evaluate its performance. 

"""

# Use a classification report to evaluate the model using the predictions and testing data
training_report = classification_report(y_test,pred)

# Print the classification report
print(training_report)

# Create a new empty predictions DataFrame.

# Create a predictions DataFrame
predictions_df = pd.DataFrame(index = X_test.index)

# Add the SVM model predictions to the DataFrame
predictions_df["Predictions"] = pred

# Add the actual returns to the DataFrame
predictions_df["Actual Returns"] = G_signals_df["Actual Returns"]

# Add the strategy returns to the DataFrame
predictions_df["Algorithm Returns"] = predictions_df["Predictions"] * predictions_df["Actual Returns"]

# Review the DataFrame
predictions_df

# Plot the actual returns versus the strategy returns
returns_plot2 = (1 + predictions_df[["Actual Returns","Algorithm Returns"]]).cumprod().hvplot()
returns_plot2